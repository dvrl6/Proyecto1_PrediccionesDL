# Proyecto1_PrediccionesDL
Modelo de Deep Learning y WebApp para la predicci√≥n de riesgo de c√°ncer de h√≠gado. 

## üìù Descripci√≥n del Proyecto

Este repositorio contiene el c√≥digo fuente para una aplicaci√≥n web dise√±ada para predecir el riesgo de un paciente de desarrollar c√°ncer de h√≠gado. La soluci√≥n completa abarca desde la ingenier√≠a de datos y el entrenamiento de un modelo de Deep Learning hasta el despliegue de una API REST y una interfaz web para el usuario final.

El objetivo principal es proporcionar una herramienta funcional que asista al personal cl√≠nico, ofreciendo una predicci√≥n probabil√≠stica y una recomendaci√≥n de acci√≥n clara basada en el riesgo calculado.

üéØ Fase 1: Ingenier√≠a de Datos y Desarrollo del Modelo DL (Python)
-----

## üìÇ Estructura del Directorio

El c√≥digo para esta fase se encuentra √≠ntegramente en la carpeta `fase_1_modelo/` y est√° organizado de la siguiente manera:

```
fase_1_modelo/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ datos/
‚îÇ   ‚îî‚îÄ‚îÄ liver_cancer_dataset.csv      # Dataset limpio y procesado.
‚îÇ
‚îú‚îÄ‚îÄ üìÇ artefactos_guardados/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.joblib           # Pipeline de preprocesamiento listo para usar.
‚îÇ   ‚îî‚îÄ‚îÄ liver_cancer_model.keras      # Modelo de Keras entrenado.
‚îÇ
‚îú‚îÄ‚îÄ üìú 00_parsear_sql.py             # Script para convertir el .sql inicial a .csv.
‚îú‚îÄ‚îÄ üìì 01_eda.ipynb                   # Notebook con el An√°lisis Exploratorio de Datos (EDA).
‚îú‚îÄ‚îÄ üìú 02_preprocesamiento.py         # Script que define y guarda el pipeline de preprocesamiento.
‚îú‚îÄ‚îÄ üìú 03_entrenamiento.py            # Script que busca hiperpar√°metros y entrena el modelo final.
‚îú‚îÄ‚îÄ üìú 04_evaluacion.py               # Script para evaluar el rendimiento del modelo guardado.
‚îî‚îÄ‚îÄ üìã requirements.txt              # Dependencias de Python para esta fase.
```

-----

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

Sigue estos pasos para configurar el entorno y poder ejecutar los scripts de esta fase.

**1. Prerrequisitos**

  * Python 3.8+
  * Git y GitHub Desktop instalados.

**2. Clonar el Repositorio**
Abre GitHub Desktop, ve a `File > Clone Repository` y selecciona este repositorio para descargarlo a tu m√°quina local.

**3. Configurar el Entorno Virtual**
Es fundamental trabajar dentro de un entorno virtual para no afectar otras instalaciones de Python. Abre una terminal en la ra√≠z del proyecto y ejecuta:

```bash
# Navega a la carpeta de la fase 1
cd fase_1_modelo

# Crea el entorno virtual (solo la primera vez)
python -m venv venv

# Activa el entorno virtual
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate
```

**4. Instalar Dependencias**
Con el entorno activado, instala todas las librer√≠as necesarias ejecutando:

```bash
pip install -r requirements.txt
```

-----

## üöÄ Uso y Ejecuci√≥n de Scripts

Para replicar los resultados de la Fase 1, ejecuta los scripts en el siguiente orden desde la terminal, asegur√°ndote de estar ubicado en la carpeta `fase_1_modelo/`.

**Paso 1: Parsear los Datos**
Este script convierte el archivo `.sql` en un `.csv` limpio. Solo necesitas ejecutarlo una vez.

```bash
python 00_parsear_sql.py
```

**Paso 2: Explorar los Datos (Opcional)**
Para visualizar el an√°lisis, abre el archivo `01_eda.ipynb` en VS Code o Jupyter.

**Paso 3: Crear el Pipeline de Preprocesamiento**
Este script aprende las transformaciones de los datos de entrenamiento y guarda el pipeline.

```bash
python 02_preprocesamiento.py
```

**Paso 4: Entrenar el Modelo**
Este es el paso principal. Ejecuta la b√∫squeda de hiperpar√°metros y guarda el mejor modelo encontrado. **Este proceso puede tardar varios minutos.**

```bash
python 03_entrenamiento.py
```

**Paso 5: Evaluar el Modelo Final**
Este script carga los artefactos guardados (`preprocessor` y `model`) y muestra las m√©tricas de rendimiento (Accuracy, AUC, Matriz de Confusi√≥n) sobre el conjunto de datos de prueba.

```bash
python 04_evaluacion.py
```

-----

## ‚úÖ Entregables para la Fase 2 (Back-end)

La ejecuci√≥n exitosa de los scripts de esta fase genera los siguientes artefactos, ubicados en la carpeta `fase_1_modelo/artefactos_guardados/`. Estos son los √∫nicos archivos que el equipo de Back-end necesita para construir la API de predicci√≥n:

1.  **`preprocessor.joblib`**: Objeto `ColumnTransformer` que contiene toda la l√≥gica para transformar los datos de entrada del usuario al formato que el modelo espera.
2.  **`liver_cancer_model.keras`**: El modelo de Deep Learning final, entrenado, optimizado y listo para hacer predicciones.
